{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from student_model_new import Knowledge_distiller, SimilarityLoss\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ProjectionHead class\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim,\n",
    "        projection_dim=512,  # Update the projection dimension\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        projected = self.projection(x)\n",
    "        x = self.gelu(projected)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + projected  # skip connection\n",
    "        x = self.layer_norm(x)  # Layer Normalization\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student feature extractor + Classifier\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self,num_classes, hidden_layers=512):\n",
    "        super(StudentNet, self).__init__()\n",
    "\n",
    "        # download resnet152 model\n",
    "        model = models.resnet152(pretrained=False)\n",
    "        self.cropped_resnet152 = torch.nn.Sequential(*list(model.children())[:-2])\n",
    "        self.projection_head = ProjectionHead(2048, projection_dim=512, dropout=0.1)\n",
    "\n",
    "        # for classifier\n",
    "        self.fc = nn.Linear(hidden_layers, num_classes)\n",
    "\n",
    "    def forward(self, image):\n",
    "        #feature extractor\n",
    "        img_embedding = self.cropped_resnet152(image)\n",
    "        image_embedding = img_embedding.view(len(img_embedding), 2048, 49)#(b,2048,49)\n",
    "        image_embedding = image_embedding.permute(0, 2, 1)#(b,49,2048)\n",
    "        image_embedding = self.projection_head(image_embedding)#(b,49,512)\n",
    "        image_embedding = image_embedding.permute(1, 0, 2)#(49,b,512)\n",
    "        #classifier\n",
    "        x = torch.mean(image_embedding, dim=0)#(1,b,512)\n",
    "        x = torch.unsqueeze(x,0)#(b,512)-----------------------------------//////\n",
    "        logit = self.fc(x)\n",
    "\n",
    "        return image_embedding, logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function for knowledge distillation\n",
    "class SimilarityLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimilarityLoss, self).__init__()\n",
    "\n",
    "    def forward(self, teacher_em, student_em):#(b,512,49)\n",
    "        batch_cs = torch.zeros(teacher_em.shape[0])  # tensor to hold cs for each feature\n",
    "        for i in range(teacher_em.shape[0]):\n",
    "            feature_cs = F.cosine_similarity(teacher_em[i, :, :], student_em[i, :, :], dim=1)\n",
    "            mean_cs = torch.mean(feature_cs)\n",
    "            batch_cs[i] = mean_cs\n",
    "\n",
    "        mean_batch_cs = torch.mean(batch_cs)\n",
    "        final_loss = 1 - mean_batch_cs\n",
    "        return final_loss ##a value between 0 & 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main model for knowledge distillation\n",
    "class Knowledge_distiller(nn.Module):\n",
    "    def __init__(self, model_path=\"path_to_teacher\", num_classes=2):\n",
    "        super(Knowledge_distiller, self).__init__()\n",
    "\n",
    "        self.student_net = StudentNet(num_classes=num_classes)\n",
    "\n",
    "        #resnet teacher model\n",
    "        model = models.resnet152(pretrained=True)#152\n",
    "        self.teacher_img_net = torch.nn.Sequential(*list(model.children())[:-2])\n",
    "        self.projection_head = ProjectionHead(2048, projection_dim=512, dropout=0.1)\n",
    "        \n",
    "        #freezing the teacher\n",
    "        for param in self.teacher_img_net.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        #Moving networks to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            self.student_net = self.student_net.to(\"cuda:0\")\n",
    "            self.teacher_img_net = self.teacher_img_net.to(\"cuda:0\")\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        teacher_img_emb = self.teacher_img_net(image)\n",
    "        teacher_img_emb = teacher_img_emb.view(len(teacher_img_emb), 2048, 49)#(b,2048,49)\n",
    "        teacher_img_emb = teacher_img_emb.permute(0, 2, 1)#(b,49,2048)\n",
    "        teacher_img_emb = self.projection_head(teacher_img_emb)#(b,49,512)\n",
    "        teacher_img_emb = teacher_img_emb.permute(0, 2, 1)#(b,512,49)\n",
    "\n",
    "        student_img_emb, prediction = self.student_net(image)#(49,b,512)\n",
    "        student_img_emb = student_img_emb.permute(1, 2, 0)#(b,512,49)\n",
    "\n",
    "        return  teacher_img_emb, student_img_emb, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_size = 224\n",
    "trainset_size = 0.99\n",
    "Epochs = 5\n",
    "training_loss = []\n",
    "saved_teacher_net_path = \"/data/ood/teacher_model_13_11/checkpoints/model_epoch_10.pt\"\n",
    "\n",
    "# Define batch_size\n",
    "batch_size = 16\n",
    "\n",
    "DIR = {\n",
    "        \"P\": \"/data/ood/PACS/pacs_data/pacs_data/photo\",\n",
    "        \"A\": \"/data/ood/PACS/pacs_data/pacs_data/art_painting\",\n",
    "        \"C\": \"/data/ood/PACS/pacs_data/pacs_data/cartoon\",\n",
    "        \"S\": \"/data/ood/PACS/pacs_data/pacs_data/sketch\",\n",
    "    }\n",
    "\n",
    "# PACS classes\n",
    "labels = {\n",
    "        \"0\": \"Dog\",\n",
    "        \"1\": \"Elephant\",\n",
    "        \"2\": \"Giraffe\",\n",
    "        \"3\": \"Guitar\",\n",
    "        \"4\": \"Horse\",\n",
    "        \"5\": \"House\",\n",
    "        \"6\": \"Person\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    train_data_dir_1,\n",
    "    train_data_dir_2,\n",
    "    train_data_dir_3,\n",
    "    valid_data_dir,\n",
    "    batch_size,\n",
    "    random_seed=38,\n",
    "    valid_size=0.9,#train_size is not 0.1 it comes from totaly seperate domain\n",
    "    shuffle=True,\n",
    "):\n",
    "    \n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "    \n",
    "\n",
    "    # define transforms\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((Image_size, Image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_dataset_1 = ImageFolder(root=train_data_dir_1, transform=transform)\n",
    "    train_dataset_2 = ImageFolder(root=train_data_dir_2, transform=transform)\n",
    "    train_dataset_3 = ImageFolder(root=train_data_dir_3, transform=transform)\n",
    "    valid_dataset = ImageFolder(root=valid_data_dir, transform=transform)\n",
    "\n",
    "    #train_dataset = train_dataset_1 + train_dataset_2 + train_dataset_3\n",
    "    train_dataset = train_dataset_1\n",
    "\n",
    "    train_indices, _ = train_test_split(\n",
    "        list(range(len(train_dataset))),\n",
    "        train_size=trainset_size,\n",
    "        random_state=random_seed,\n",
    "    )\n",
    "    valid_indices, _ = train_test_split(\n",
    "        list(range(len(valid_dataset))), train_size=valid_size, random_state=random_seed\n",
    "    )\n",
    "\n",
    "    # Create DataLoader for train and test sets\n",
    "    train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "    valid_dataset = torch.utils.data.Subset(valid_dataset, valid_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # set the relevant domain as train, valid sets\n",
    "train_dataloader, validation_dataloader= data_loader(\n",
    "        DIR[\"P\"],   #train\n",
    "        DIR[\"A\"],   #train\n",
    "        DIR[\"C\"],   #train\n",
    "        DIR[\"P\"],   #validation\n",
    "        batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 : 11.19%\n",
      "Class 1 : 12.04%\n",
      "Class 2 : 10.95%\n",
      "Class 3 : 11.19%\n",
      "Class 4 : 11.92%\n",
      "Class 5 : 16.76%\n",
      "Class 6 : 25.95%\n"
     ]
    }
   ],
   "source": [
    "number_count=[0,0,0,0,0,0,0]\n",
    "for batch, (image, label) in enumerate((train_dataloader)):\n",
    "    for i in label:\n",
    "        number_count[int(i)]+=1\n",
    "\n",
    "for i,j in enumerate(number_count):\n",
    "    print(f\"Class {i} : {j*100/sum(number_count):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to save embeddings to do PCA\n",
    "text_embedding_global = []\n",
    "S_img_embedding_global = []\n",
    "T_img_embedding_global = []\n",
    "label_set = []\n",
    "epoch_flag = False  # flag to identify last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available() #check whether multi process service is enabled\n",
    "        else \"cpu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded to GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "        model = Knowledge_distiller(num_classes=7,model_path=saved_teacher_net_path)\n",
    "        model = model.to(\"cuda:0\")  # model moved to specified GPU\n",
    "        print(\"Model loaded to GPU.\")\n",
    "else:\n",
    "        model = Knowledge_distiller(num_classes=7,model_path=saved_teacher_net_path)\n",
    "        print(\"GPU is unavailable. model loaded to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_1 = SimilarityLoss()  # Loss function for knowledge distillation\n",
    "criterion_2 = nn.CrossEntropyLoss()  # Loss function for classifier\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define a directory to save your model and checkpoints\n",
    "save_dir = \"Model_checkpoints_for_distiller\"\n",
    "\n",
    "# Make sure the directory exists, create it if it doesn't\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training only student network (classifier-> frozen)\n",
    "for name, param in model.named_parameters():\n",
    "    if name in [\"student_net.fc.weight\", \"student_net.fc.bias\"]:\n",
    "        param.requires_grad = False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        filename=\"Distillation.log\",\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f129b850d9154bc6914b14b8549f29a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3959463c41244c2fa259acedfbab6174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 0.05128302797675133\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e971530e9a9d41c5982000ad2cf1e4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss: 0.0026086282450705767\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38195af3d2394b4b9adc7381d65b3f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss: 0.0010389857925474644\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd77b0ec4bb94fbd81b1c84482ec25f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss: 0.0006129953544586897\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854d6d409d4a475b90b47aeecd44cc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss: 0.00046085394569672644\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(Epochs)):\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    for batch, (image, label) in enumerate(tqdm(train_dataloader)):\n",
    "        if epoch_flag:\n",
    "            label_set.append(label.detach().numpy())\n",
    "        label_tensor = []\n",
    "        for idx, val in enumerate(label):\n",
    "            label_tensor.append(labels[str(label[idx].item())])\n",
    "\n",
    "        # Moving Img_data to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.to(\"cuda:0\")\n",
    "            \n",
    "        #print(\"Label {}\".format(label))\n",
    "        teacher_img_emb, student_img_emb,_ = model(image, label)\n",
    "\n",
    "        # Calculating loss\n",
    "        loss = criterion_1(teacher_img_emb, student_img_emb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss\n",
    "\n",
    "\n",
    "    if i == Epochs - 2:\n",
    "        epoch_flag = True\n",
    "\n",
    "    training_loss.append(\n",
    "        (epoch_loss / len(train_dataloader)).cpu().detach().numpy()\n",
    "    )\n",
    "    # Print average loss for a batch in each epoch\n",
    "    print(f\"Epoch {i+1}: Loss: {training_loss[-1]}\\n\\n\")\n",
    "\n",
    "    # Save the model and training checkpoint\n",
    "    if (i + 1) % 2 == 0:  # Save every 2 epochs, adjust as needed\n",
    "        # Save the model's state dictionary\n",
    "        model_checkpoint_path = os.path.join(save_dir, f\"model_epoch_{i+1}.pt\")\n",
    "        # torch.save(model.state_dict(), model_checkpoint_path)\n",
    "\n",
    "        # Save training checkpoint information\n",
    "        checkpoint = {\n",
    "            \"epoch\": i + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": training_loss[-1],\n",
    "        }\n",
    "        checkpoint_path = os.path.join(save_dir, f\"checkpoint_epoch_{i+1}.pt\")\n",
    "        # torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "        # Log the saved paths and other details\n",
    "        logging.info(f\"Epoch {i+1} - Model saved to: {model_checkpoint_path}\")\n",
    "        logging.info(f\"Epoch {i+1} - Checkpoint saved to: {checkpoint_path}\")\n",
    "\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# freezing feature extractor\n",
    "for name, param in model.named_parameters():\n",
    "    if name in [\"student_net.fc.weight\", \"student_net.fc.bias\"]:\n",
    "        param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a directory to save your model and checkpoints\n",
    "save_dir = \"Model_checkpoints_for_classifier\"\n",
    "\n",
    "# Make sure the directory exists, create it if it doesn't\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "## Training for the classifier by freezing feature extractor\n",
    "training_loss = []\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"Classification.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs  = 20\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8118002434bb4583bad4c182888d3e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad4a75c688b4a329e767ec0bfa9bfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 5, 6, 3, 5], device='cuda:0')\n",
      "Epoch 1: Loss: 1.666720986366272\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4400da4c8fb4b89a09c9db53feb6e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 3, 6, 1, 1], device='cuda:0')\n",
      "Epoch 2: Loss: 1.3974285125732422\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6a0bb6a214427290da4b14d99abee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 2, 0, 6], device='cuda:0')\n",
      "Epoch 3: Loss: 1.2905151844024658\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7356243f03cc4890a5f56ff9090213de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 6, 1, 6], device='cuda:0')\n",
      "Epoch 4: Loss: 1.159075379371643\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9445c41e1141cb8a94ebd14a1b9eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 5, 4, 1], device='cuda:0')\n",
      "Epoch 5: Loss: 1.1306816339492798\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ec434436694dd2a991b6570a56c322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 6, 5, 3, 6], device='cuda:0')\n",
      "Epoch 6: Loss: 1.132980465888977\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a60a1655a4427ba36a8af2d73326a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 5, 1, 3, 5], device='cuda:0')\n",
      "Epoch 7: Loss: 1.1160430908203125\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7686a5589e4d6884b20cbf3dfbaa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 6, 6, 6], device='cuda:0')\n",
      "Epoch 8: Loss: 1.0364614725112915\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75db4ac7c11142cca10b969b0ad37180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 6, 4, 5, 6], device='cuda:0')\n",
      "Epoch 9: Loss: 1.0218942165374756\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126f91510dce49c685bb90b460c6f47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 4, 3, 6], device='cuda:0')\n",
      "Epoch 10: Loss: 0.9699264168739319\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491128e486db4069b32a79418cf043b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 2, 5, 1, 3], device='cuda:0')\n",
      "Epoch 11: Loss: 1.021360993385315\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451b180e6ff943b1864c6871908674b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 6, 3, 2, 2], device='cuda:0')\n",
      "Epoch 12: Loss: 0.9324161410331726\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e96dd10c86a4f608f61c952f77c0599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 5, 0, 0, 6], device='cuda:0')\n",
      "Epoch 13: Loss: 0.9081798791885376\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32150c48f7f54194bd74035ade66124e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 5, 4, 6], device='cuda:0')\n",
      "Epoch 14: Loss: 0.8608699440956116\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b46b62f5334c35a544644ef9f8bcd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 1, 5, 1, 6], device='cuda:0')\n",
      "Epoch 15: Loss: 0.8248481154441833\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79513a15a2a046db9ad35eae5147448c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 6, 5, 5], device='cuda:0')\n",
      "Epoch 16: Loss: 0.774986743927002\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dbd73e1ed544f589b0fee9880d7d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 6, 6, 0, 0], device='cuda:0')\n",
      "Epoch 17: Loss: 0.783867359161377\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1219b8a130bc4016a85cdf39f020db77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 6, 5, 6, 6], device='cuda:0')\n",
      "Epoch 18: Loss: 0.8021409511566162\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3172a61cf41417693ae83ea25c4401e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 6, 3, 4], device='cuda:0')\n",
      "Epoch 19: Loss: 0.730690598487854\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66efbea651154110a9d911ebfa526f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 1, 6, 3, 5], device='cuda:0')\n",
      "Epoch 20: Loss: 0.7032714486122131\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(Epochs)):\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    for batch, (image, label) in enumerate(tqdm(train_dataloader)):\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.to(\"cuda:0\")\n",
    "\n",
    "        imgt,imgs, logits = model(image,label)\n",
    "        logits = torch.squeeze(logits,0)\n",
    "        if torch.cuda.is_available():\n",
    "            label = label.to(\"cuda:0\")\n",
    "        loss = criterion_2(logits, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss\n",
    "\n",
    "    print(torch.argmax(logits,dim=1))\n",
    "    training_loss.append(\n",
    "        (epoch_loss / len(train_dataloader)).cpu().detach().numpy()\n",
    "    )\n",
    "    print(f\"Epoch {i+1}: Loss: {training_loss[-1]}\\n\\n\")\n",
    "\n",
    "    # Save the model's state dictionary\n",
    "    model_checkpoint_path = os.path.join(save_dir, f\"model_epoch_{i+1}.pt\")\n",
    "    # torch.save(model.state_dict(), model_checkpoint_path)\n",
    "\n",
    "    # Save training checkpoint information\n",
    "    checkpoint = {\n",
    "        \"epoch\": i + 1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": training_loss[-1],\n",
    "    }\n",
    "    checkpoint_path = os.path.join(save_dir, f\"checkpoint_epoch_{i+1}.pt\")\n",
    "    # torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "    # Log the saved paths and other details\n",
    "    logging.info(f\"Epoch {i+1} - Model saved to: {model_checkpoint_path}\")\n",
    "    logging.info(f\"Epoch {i+1} - Checkpoint saved to: {checkpoint_path}\")\n",
    "\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d134d7896146dca7dbf5c1f60933a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6445\n",
      "Validation Accuracy: 74.45%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epoch_flag = False\n",
    "total_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "i=0\n",
    "for batch, (image, label) in enumerate(tqdm(validation_dataloader)):     \n",
    "        # Moving Img_data to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.to(\"cuda:0\")\n",
    "\n",
    "        imgt,imgs,prediction = model(image,label)\n",
    "        prediction =torch.squeeze(prediction,0)\n",
    "        loss = criterion_2(prediction.cpu(), label)\n",
    "        total += label.size(0)\n",
    "        predict_labels = torch.argmax(prediction, dim=1)\n",
    "        predict_labels = torch.tensor(predict_labels,dtype = int)\n",
    "        predict_eval_list = [a == b for a, b in zip(predict_labels, label)]\n",
    "        correct += sum(predict_eval_list)\n",
    "        total_loss += loss.item()\n",
    "validation_loss = total_loss / len(validation_dataloader)\n",
    "validation_accuracy = 100 * correct / total\n",
    "print(f\"Validation Loss: {validation_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {validation_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
